# sabim_ai_tools/llms_ultilities.py

# Required packages
import ollama
import json

# Default prompt for title and abstracts of articles analysis
prompt = {}


class llm_analysis():

    def __init__(self, data, model="llama3.2:1b", api_key = None):
        """
        init class

        Args:   
            - data(pd.dataframe): data for analyse.  
            - model(str): Model for use in the analysis. Defaults to llama3.2:1b. 
            - api_key(str): API key for in case of use non-local model. Defaults to None.
        """
        self.data = data;  self.model = model; self.api_key = api_key

    def model_call(self):
        """
        Initializes and returns an instance of the LLM model.

        Returns:       
            object: The Llama3 model instance.
        """
        if self.model == "genai":
            raise ValueError("Not implemented yet...")
        elif self.model == "llama3.2:1b" or self.model == "llama3.2:3b" or self.model == "llama3.1:8b":
            return ollama
        else:   
            raise ValueError("The current code only suports google germini (genai) or llama3.2:1b, llama3.2:3b, and llama3.1:8b models. Please provide the correct model.")

    def model_interaction(self, title, abstract, tamplate, prompt, content = None, task = "T&A"):

        """
        Interacts with an LLM model to generate a response based on a provided structure, using a specific prompt structure.

        Arguments:
            title (str): The title of the article or paper.
            abstract (str): The abstract of the article or paper.
            model (object): The AI model instance used to generate the response.
            template (dict): A dictionary defining the structure for the AI's response.
            prompt (dict): A dictionary containing the prompt header and instructions. Defaults to a predefined 'prompt'.

        Returns:
            str: The content generated by the AI model in response to the provided input.
        """

        model = self.model_call()

        if task != "T&A":
            raise ValueError("Currently this code only analyses articles abstracts and titles. Other freatures will come soon!")

        else: 
            # Construct the input prompt by combining the header, title, abstract, instructions, and template
            input_ai = (
                f"{prompt['prompt_header']} \n"
                f"Title: {title} \n"
                f"Abstract: {abstract} \n"
                f"{prompt['prompt_instructions']} \n"
                f"Use the following template: {json.dumps(self.template)}."
                        )
            
            return model.chat(model=self.model, 
                              messages=[{"role": "user", "content": f"{input_ai}"}],
                             )





    

