# sabim_ai_tools/llms_ultilities.py

# Required packages
import ollama
import json
import re

# Default prompt for title and abstracts of articles analysis
prompt = {}

class llm_analysis():

    def __init__(self, data, model="llama3.2:1b", api_key = None):
        """
        init class

        Args:   
            - data(pd.dataframe): data for analyse.  
            - model(str): Model for use in the analysis. Defaults to llama3.2:1b. 
            - api_key(str): API key for in case of use non-local model. Defaults to None.
        """
        self.data = data;  self.model = model; self.api_key = api_key

    def model_call(self):
        """
        Initializes and returns an instance of the LLM model.

        Returns:       
            object: The Llama3 model instance.
        """
        if self.model == "genai":
            raise ValueError("Not implemented yet...")
        elif self.model == "llama3.2:1b" or self.model == "llama3.2:3b" or self.model == "llama3.1:8b":
            return ollama
        else:   
            raise ValueError("The current code only suports google germini (genai) or llama3.2:1b, llama3.2:3b, and llama3.1:8b models. Please provide the correct model.")

    def model_interaction(self, title, abstract, tamplate, prompt, content = None, task = "T&A"):

        """
        Interacts with an LLM model to generate a response based on a provided structure, using a specific prompt structure.

        Arguments:
            title (str): The title of the article or paper.
            abstract (str): The abstract of the article or paper.
            model (object): The AI model instance used to generate the response.
            template (dict): A dictionary defining the structure for the AI's response.
            prompt (dict): A dictionary containing the prompt header and instructions. Defaults to a predefined 'prompt'.

        Returns:
            str: The content generated by the AI model in response to the provided input.
        """

        model = self.model_call()

        if task != "T&A":
            raise ValueError("Currently this code only analyses articles abstracts and titles. Other freatures will come soon!")

        else: 
            # Construct the input prompt by combining the header, title, abstract, instructions, and template
            input_ai = (
                f"{prompt['prompt_header']} \n"
                f"Title: {title} \n"
                f"Abstract: {abstract} \n"
                f"{prompt['prompt_instructions']} \n"
                f"Use the following template: {json.dumps(self.template)}."
                        )
            
            return model.chat(model=self.model, 
                              messages=[{"role": "user", "content": f"{input_ai}"}],
                             )

    def parse_ai_response_json(self, ai_response):
        """
        Parse the AI response, identifying and extracting the JSON part according to the predefined template structure.

        Args:
            ai_response (str): The AI-generated response, which may contain both plain text and a JSON-formatted part.

        Returns:
            dict: A dictionary containing the parsed content of each section according to the template.
                Example:
                {
                    "Systems": [...],
                    "Type": "...",
                    "Methods": [...],
                    "Main Scope": "...",
                    "Main Results": "...",
                    "Keywords": [...]
                }
        """

        # Use regex to identify the JSON part in the response
        json_match = re.search(r'\{.*?\}', ai_response, re.DOTALL)

        if json_match:
            # Extract the JSON part from the response
            json_part = json_match.group(0)
        
            try:
                # Convert the JSON string to a dictionary
                parsed_data = json.loads(json_part)
                
                # Ensure that the parsed data matches the expected template format
                template_keys =  self.template.keys() 
                
                result = {key: parsed_data.get(key, []) if isinstance(parsed_data.get(key), list) else parsed_data.get(key, "")
                        for key in template_keys}
                
                return result
            
            except json.JSONDecodeError:
                # Handle case where JSON is malformed or not decodable
                print("Error decoding JSON part of the AI response.")
                return None
        else:
            print("No JSON part found in the AI response.")
            return None
    

